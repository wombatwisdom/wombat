---
title: openai_translation
kind: processor
---
import { Aside } from '@astrojs/starlight/components';
import { Tabs, TabItem } from '@astrojs/starlight/components';

Translates spoken audio into English, using the OpenAI API.

Introduced in version 4.32.0.


<Tabs>
<TabItem label="Common">
```yml
# Common config fields, showing default values
label: ""
openai_translation:
  server_address: https://api.openai.com/v1
  api_key: "" # No default (required)
  model: whisper-1 # No default (required)
  file: "" # No default (optional)
```
</TabItem>
<TabItem label="Advanced">
```yml
# Advanced config fields, showing default values
label: ""
openai_translation:
  server_address: https://api.openai.com/v1
  api_key: "" # No default (required)
  model: whisper-1 # No default (required)
  file: "" # No default (optional)
  prompt: "" # No default (optional)
```
</TabItem>
</Tabs>

This processor sends an audio file object to OpenAI API to generate a translation. By default, the processor submits the entire payload of each message as a string, unless you use the `file` configuration field to customize it.

To learn more about translation, see the [OpenAI API documentation](https://platform.openai.com/docs/guides/speech-to-text).

## Fields

### `server_address`

The Open API endpoint that the processor sends requests to. Update the default value to use another OpenAI compatible service.


*Type*: `string`

*Default*: `"https://api.openai.com/v1"`

### `api_key`

The API key for OpenAI API.
<Aside type="caution" title="Sensitive Information">
	This field contains sensitive information that usually shouldn't be added to a config directly, read our secrets page for more info.
</Aside>



*Type*: `string`


### `model`

The name of the OpenAI model to use.


*Type*: `string`


```yml
# Examples

model: whisper-1
```

### `file`

The audio file object (not file name) to translate, in one of the following formats: `flac`, `mp3`, `mp4`, `mpeg`, `mpga`, `m4a`, `ogg`, `wav`, or `webm`.


*Type*: `string`


### `prompt`

Optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.
This field supports interpolation functions.


*Type*: `string`



